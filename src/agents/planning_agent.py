# 1. å¯¼å…¥å¿…è¦æ¨¡å—
from dotenv import load_dotenv
load_dotenv()
from langchain_deepseek import ChatDeepSeek
from langchain.agents import create_agent
from langgraph.checkpoint.memory import InMemorySaver

# å¯¼å…¥å·¥å…· (åˆšæ‰å†™å¥½çš„ RAG å·¥å…·)
from src.rag.tool import planning_knowledge_tool

# --- æ ¸å¿ƒç»„ä»¶è®¾ç½® ---
# è¿™é‡ŒåªåŠ è½½è§„åˆ’ç›¸å…³çš„å·¥å…·ï¼Œä¿æŒä¸“å®¶çº¯åº¦
tools = [planning_knowledge_tool]
llm = ChatDeepSeek(model="deepseek-chat", temperature=0)
memory = InMemorySaver()

# --- æ–°çš„ç³»ç»Ÿæç¤ºè¯ (XMLç»“æ„ - è§„åˆ’ä¸“å®¶ç‰ˆ) ---
SYSTEM_PROMPT = """
<role>
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ä¹¡æ‘æŒ¯å…´è§„åˆ’å’¨è¯¢ä¸“å®¶ï¼Œä¸“é—¨æœåŠ¡äºâ€œåšç½—å¤åŸ-é•¿å®é•‡-ç½—æµ®å±±â€åŒºåŸŸçš„èåˆé«˜è´¨é‡å‘å±•æˆ˜ç•¥ã€‚ä½ ç†Ÿæ‚‰è¯¥åŒºåŸŸçš„æ€»ä½“è§„åˆ’ã€äº§ä¸šå¸ƒå±€ã€æ–‡åŒ–èƒŒæ™¯åŠæ”¿ç­–æ–¹é’ˆã€‚ä½ çš„èŒè´£æ˜¯åŸºäºçŸ¥è¯†åº“ä¸­çš„æ–‡æ¡£ï¼Œå‡†ç¡®å›ç­”ç”¨æˆ·çš„å’¨è¯¢ã€‚
</role>

<tools>
ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·ï¼š
- search_planning_strategyï¼šæŸ¥è¯¢åšç½—å¤åŸã€é•¿å®é•‡åŠç½—æµ®å±±ç›¸å…³çš„è§„åˆ’èµ„æ–™ã€‚
  - è¾“å…¥ï¼šæŸ¥è¯¢å…³é”®è¯æˆ–å…·ä½“é—®é¢˜ï¼ˆå¦‚â€œç½—æµ®å±±æˆ˜ç•¥å®šä½â€ã€â€œé•¿å®é•‡ä¸€è½´ä¸¤å¸¦â€ï¼‰
  - è¾“å‡ºï¼šç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µã€é¡µç åŠå…·ä½“å†…å®¹
</tools>

<task>
å½“ç”¨æˆ·æå‡ºé—®é¢˜æ—¶ï¼Œè¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹æµç¨‹å·¥ä½œï¼š
1. **åˆ†ææ„å›¾**ï¼šç†è§£ç”¨æˆ·æƒ³è¦äº†è§£çš„æ˜¯è§„åˆ’èƒŒæ™¯ã€å…·ä½“æ”¿ç­–è¿˜æ˜¯ç©ºé—´å¸ƒå±€ã€‚
2. **æŸ¥é˜…èµ„æ–™**ï¼š**å¿…é¡»**ä¼˜å…ˆè°ƒç”¨ `search_planning_strategy` å·¥å…·è¿›è¡Œæ£€ç´¢ï¼Œè·å–å‡†ç¡®ä¿¡æ¯ã€‚
3. **æ•´åˆä¿¡æ¯**ï¼šé˜…è¯»å·¥å…·è¿”å›çš„æ–‡æ¡£ç‰‡æ®µï¼Œæå–æ ¸å¿ƒè§‚ç‚¹ã€‚
4. **ä¸“ä¸šè§£ç­”**ï¼š
   - åŸºäºæ£€ç´¢åˆ°çš„å†…å®¹å›ç­”ç”¨æˆ·ã€‚
   - å›ç­”è¦æœ‰æ¡ç†ï¼ˆä½¿ç”¨ 1. 2. 3. åˆ†ç‚¹é™ˆè¿°ï¼‰ã€‚
   - **å¼•ç”¨æ¥æº**ï¼šå¦‚æœå¯èƒ½ï¼Œè¯·åœ¨å›ç­”ä¸­æ³¨æ˜ä¿¡æ¯æ¥æºï¼ˆä¾‹å¦‚ï¼šâ€œæ ¹æ®è§„åˆ’è¯´æ˜ä¹¦ç¬¬Xé¡µ...â€ï¼‰ã€‚
</task>

<constraints>
- **ä¸¥ç¦ç¼–é€ **ï¼šè¿™ä¸€æ¡è‡³å…³é‡è¦ã€‚å¦‚æœå·¥å…·æ£€ç´¢ç»“æœä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯šå®åœ°å‘Šè¯‰ç”¨æˆ·â€œç°æœ‰è§„åˆ’èµ„æ–™ä¸­æœªæåŠæ­¤äº‹â€ï¼Œç»å¯¹ä¸è¦æ ¹æ®å¸¸è¯†çç¼–ã€‚
- **ä¿æŒå®¢è§‚**ï¼šå›ç­”åº”åŸºäºè§„åˆ’æ–‡ä»¶çš„åŸæ–‡ç²¾ç¥ã€‚
- **è¯­æ°”ä¸“ä¸š**ï¼šä¿æŒæ”¿åºœé¡¾é—®æˆ–é«˜çº§è§„åˆ’å¸ˆçš„ä¸“ä¸šã€ä¸¥è°¨è¯­æ°”ã€‚
</constraints>
"""

# --- åˆ›å»º Agent ---
agent = create_agent(
    model=llm, 
    tools=tools, 
    checkpointer=memory,
    system_prompt=SYSTEM_PROMPT 
)


if __name__ == "__main__":
    import uuid
    
    # åˆ›å»ºä¸€ä¸ªéšæœºçº¿ç¨‹IDï¼Œæ¨¡æ‹Ÿä¸åŒç”¨æˆ·
    thread_id = str(uuid.uuid4())
    config = {"configurable": {"thread_id": thread_id}}

    print("ğŸ“ ä¹¡æ‘è§„åˆ’å’¨è¯¢ Agent å·²å¯åŠ¨ï¼(è¾“å…¥ 'q' é€€å‡º)")
    print("---------------------------------------------")
    
    while True:
        user_input = input("\nğŸ‘¤ è¯·æé—® (e.g. é•¿å®é•‡çš„å‘å±•ç›®æ ‡æ˜¯ä»€ä¹ˆ?): ").strip()
        if user_input.lower() in ["q", "exit", "quit"]:
            break
        if not user_input:
            continue
            
        print("ğŸ¤– æ­£åœ¨æ€è€ƒå¹¶æŸ¥é˜…èµ„æ–™...")
        
        # Stream æ¨¡å¼å¯ä»¥å®æ—¶çœ‹åˆ°å·¥å…·è°ƒç”¨è¿‡ç¨‹
        events = agent.stream(
            {"messages": [("user", user_input)]},
            config,
            stream_mode="values"
        )
        
        for event in events:
            # åªæ‰“å°æœ€åä¸€æ¡ AI çš„å›å¤
            if "messages" in event:
                last_msg = event["messages"][-1]
                if last_msg.type == "ai" and last_msg.content:
                    print(f"\nğŸ“ [ä¸“å®¶å›å¤]:\n{last_msg.content}")