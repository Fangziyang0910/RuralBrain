import os
from pptx import Presentation
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document

# ================= é…ç½®åŒº =================
# 1. ä½ çš„ PPT åŸå§‹è·¯å¾„ (WSL ä¸‹è®¿é—® Windows ç›˜ç¬¦)
# 1. è·å–å½“å‰è„šæœ¬ç›®å½•
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))

# 2. æŒ‡å‘åˆšæ‰å¤åˆ¶è¿›æ¥çš„ PPT (æ³¨æ„æ–‡ä»¶åå˜äº†)
PPT_PATH = os.path.join(CURRENT_DIR, "..", "data", "luofu_strategy.pptx")

# 3. æ•°æ®åº“è·¯å¾„
PROJECT_ROOT = os.path.dirname(os.path.dirname(CURRENT_DIR))
PERSIST_DIRECTORY = os.path.join(PROJECT_ROOT, "knowledge_base", "luofu_db")
# =========================================

def extract_text_from_pptx(file_path):
    """ç›´æ¥ä» PPTX æå–æ–‡å­—ï¼Œä¸è½¬ PDF"""
    if not os.path.exists(file_path):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {file_path}")
        return []

    print(f"ğŸ“‚ æ­£åœ¨è¯»å– PPT: {file_path} ...")
    prs = Presentation(file_path)
    documents = []

    for i, slide in enumerate(prs.slides):
        slide_text = []
        # éå†æ¯é¡µçš„æ‰€æœ‰æ–‡æœ¬æ¡†
        for shape in slide.shapes:
            if hasattr(shape, "text") and shape.text.strip():
                slide_text.append(shape.text.strip())
        
        page_content = "\n".join(slide_text)
        
        # åªæœ‰å½“è¿™ä¸€é¡µæœ‰å­—çš„æ—¶å€™æ‰ä¿å­˜
        if page_content:
            # åŠ ä¸Šé¡µç å…ƒæ•°æ®ï¼Œæ–¹ä¾¿ä»¥åçŸ¥é“æ˜¯å“ªä¸€é¡µ
            doc = Document(
                page_content=page_content,
                metadata={"source": "åšç½—å¤åŸæ€»ä½“è§„åˆ’è¯´æ˜ä¹¦", "page": i + 1}
            )
            documents.append(doc)
    
    print(f"âœ… æå–å®Œæˆï¼Œå…±è·å– {len(documents)} é¡µæœ‰æ•ˆå†…å®¹ã€‚")
    return documents

def build_vector_db():
    # 1. æå–æ–‡å­—
    docs = extract_text_from_pptx(PPT_PATH)
    if not docs:
        return

    # 2. åˆ‡åˆ†æ–‡æœ¬
    print("âœ‚ï¸ æ­£åœ¨åˆ‡åˆ†æ–‡æœ¬...")
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,    # æ¯å—çš„å¤§å°
        chunk_overlap=100  # é‡å éƒ¨åˆ†ï¼Œé˜²æ­¢åˆ‡æ–­å¥å­
    )
    splits = text_splitter.split_documents(docs)
    print(f"âœ‚ï¸ åˆ‡åˆ†å®Œæˆï¼Œå…± {len(splits)} ä¸ªç‰‡æ®µã€‚")

    # 3. å‘é‡åŒ–å¹¶å­˜å‚¨
    print("ğŸ§  æ­£åœ¨å‘é‡åŒ– (é¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½æ¨¡å‹ï¼Œè¯·ç¨å€™)...")
    embedding_model = HuggingFaceEmbeddings(model_name="BAAI/bge-small-zh-v1.5")

    print(f"ğŸ’¾ æ­£åœ¨å†™å…¥æ•°æ®åº“: {PERSIST_DIRECTORY}")
    vectorstore = Chroma.from_documents(
        documents=splits,
        embedding=embedding_model,
        persist_directory=PERSIST_DIRECTORY
    )
    print("ğŸ‰ æ­å–œï¼çŸ¥è¯†åº“æ„å»ºæˆåŠŸï¼")

if __name__ == "__main__":
    build_vector_db()