"""
Planning Service API è·¯ç”±
æä¾›è§„åˆ’å’¨è¯¢ã€çŸ¥è¯†åº“æŸ¥è¯¢ç­‰ç«¯ç‚¹
"""
import json
import logging
import time
import uuid
from typing import AsyncGenerator

from fastapi import APIRouter, HTTPException, status
from fastapi.responses import StreamingResponse
from langchain_core.messages import HumanMessage

from src.rag.service.core.config import (
    SERVICE_NAME,
    SERVICE_VERSION,
    LOG_LEVEL,
)
from src.rag.service.schemas.chat import (
    PlanningChatRequest,
    DocumentListResponse,
    DocumentInfo,
    DocumentSummaryResponse,
    ChapterListResponse,
    ChapterInfo,
    HealthResponse,
)
from src.rag.core.context_manager import get_context_manager

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=getattr(logging, LOG_LEVEL),
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

router = APIRouter()

# æ¨¡å¼æŒ‡ä»¤
MODE_INSTRUCTIONS = {
    "fast": "âš¡ å½“å‰ä¸ºå¿«é€Ÿæ¨¡å¼ï¼šæœ€å¤šè°ƒç”¨ 2 æ¬¡å·¥å…·ï¼Œä¼˜å…ˆä½¿ç”¨ get_document_overview å’Œ search_key_pointsï¼Œé¿å…ä½¿ç”¨ get_chapter_content å’Œ get_document_fullã€‚",
    "deep": "ğŸ” å½“å‰ä¸ºæ·±åº¦æ¨¡å¼ï¼šæœ€å¤šè°ƒç”¨ 5 æ¬¡å·¥å…·ï¼Œå¯ä»¥ä½¿ç”¨æ‰€æœ‰å·¥å…·åŒ…æ‹¬ get_chapter_content å’Œ get_document_full è¿›è¡Œæ·±åº¦åˆ†æã€‚",
    "auto": "ğŸ¤– å½“å‰ä¸ºè‡ªåŠ¨æ¨¡å¼ï¼šæ ¹æ®é—®é¢˜å¤æ‚åº¦è‡ªä¸»é€‰æ‹©å·¥ä½œæ¨¡å¼å’Œå·¥å…·ã€‚",
}


# ==================== è¾…åŠ©å‡½æ•° ====================

def extract_knowledge_sources(tool_output: str) -> list[dict]:
    """ä»å·¥å…·è¾“å‡ºä¸­æå–çŸ¥è¯†åº“æ¥æºä¿¡æ¯"""
    import re

    sources = []
    pattern = r"ã€çŸ¥è¯†ç‰‡æ®µ \d+ã€‘\s*\næ¥æº: ([^\n]+)\s*\nä½ç½®: ç¬¬(\d+)\s*(.*?)\s*\nå†…å®¹:\s*([\s\S]*?)(?=ã€çŸ¥è¯†ç‰‡æ®µ|$)"

    for match in re.findall(pattern, tool_output):
        source, page_num, doc_type, content = match
        content_preview = content.strip()[:300]
        if len(content_preview) == 300:
            content_preview += "..."

        sources.append({
            "source": source.strip(),
            "page": int(page_num),
            "doc_type": doc_type.strip() if doc_type else "",
            "content": content_preview,
        })

    return sources


# ==================== å»¶è¿ŸåŠ è½½ Agent ====================

_agent = None


def get_agent():
    """å»¶è¿ŸåŠ è½½ Planning Agent"""
    global _agent
    if _agent is None:
        logger.info("æ­£åœ¨åŠ è½½ Planning Agent...")
        from src.agents.planning_agent import agent as planning_agent
        _agent = planning_agent
        logger.info("Planning Agent åŠ è½½å®Œæˆ")
    return _agent


# ==================== æ ¸å¿ƒç«¯ç‚¹ ====================

@router.get("/health", response_model=HealthResponse, tags=["ç³»ç»Ÿ"])
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    try:
        from pathlib import Path
        from src.rag.config import CHROMA_PERSIST_DIR

        kb_loaded = Path(CHROMA_PERSIST_DIR).exists()

        return HealthResponse(
            status="healthy",
            service=SERVICE_NAME,
            version=SERVICE_VERSION,
            knowledge_base_loaded=kb_loaded,
        )
    except Exception as e:
        logger.error(f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail=f"æœåŠ¡ä¸å¯ç”¨: {str(e)}"
        )


@router.post("/chat/planning", summary="è§„åˆ’å’¨è¯¢å¯¹è¯ï¼ˆæµå¼ï¼‰", tags=["è§„åˆ’å’¨è¯¢"])
async def planning_chat(request: PlanningChatRequest):
    """è§„åˆ’å’¨è¯¢å¯¹è¯æ¥å£ï¼ˆæµå¼ï¼‰"""
    try:
        agent = get_agent()
        thread_id = request.thread_id or str(uuid.uuid4())
        config = {"configurable": {"thread_id": thread_id, "mode": request.mode}}

        logger.info(f"æ”¶åˆ°è§„åˆ’å’¨è¯¢è¯·æ±‚ [thread_id={thread_id}, mode={request.mode}]: {request.message}")

        return StreamingResponse(
            _event_generator(agent, request, thread_id, config),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no",
            }
        )

    except Exception as e:
        logger.error(f"è§„åˆ’å’¨è¯¢è¯·æ±‚å¤±è´¥: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è¯·æ±‚å¤„ç†å¤±è´¥: {str(e)}"
        )


async def _event_generator(agent, request: PlanningChatRequest, thread_id: str, config: dict) -> AsyncGenerator[str, None]:
    """SSE äº‹ä»¶ç”Ÿæˆå™¨"""
    tools_used = []
    full_content = ""
    knowledge_sources = []
    sources_sent = False
    start_time = time.time()
    tool_call_count = 0

    try:
        # å‘é€å¼€å§‹äº‹ä»¶
        yield f"data: {json.dumps({'type': 'start', 'thread_id': thread_id, 'mode': request.mode}, ensure_ascii=False)}\n\n"

        # æ„å»ºå¢å¼ºæ¶ˆæ¯
        mode_prefix = MODE_INSTRUCTIONS.get(request.mode, MODE_INSTRUCTIONS["auto"])
        enhanced_message = f"{mode_prefix}\n\nç”¨æˆ·é—®é¢˜ï¼š{request.message}"

        input_data = {
            "messages": [HumanMessage(content=enhanced_message)],
            "mode": request.mode,
        }

        # æµå¼å¤„ç† agent å“åº”
        async for event in agent.astream_events(input_data, config, version="v2"):
            kind = event["event"]

            if kind == "on_chat_model_stream":
                content = event["data"]["chunk"].content
                if content:
                    full_content += content
                    yield f"data: {json.dumps({'type': 'content', 'content': content}, ensure_ascii=False)}\n\n"

            elif kind == "on_tool_start":
                tool_name = event["name"]
                if tool_name not in tools_used:
                    tools_used.append(tool_name)
                tool_call_count += 1
                yield f"data: {json.dumps({'type': 'tool', 'tool_name': tool_name, 'status': 'started', 'tool_call_count': tool_call_count}, ensure_ascii=False)}\n\n"

            elif kind == "on_tool_end":
                tool_name = event["name"]
                tool_output = event["data"].get("output")
                output_str = str(tool_output.content) if hasattr(tool_output, "content") else str(tool_output)

                logger.info(f"å·¥å…· {tool_name} è¾“å‡ºé¢„è§ˆ: {output_str[:200]}...")

                # æå–çŸ¥è¯†åº“æ¥æº
                extracted_sources = extract_knowledge_sources(output_str)

                if tool_name == "search_knowledge":
                    logger.info(f"[DEBUG] search_knowledge è¾“å‡ºé•¿åº¦: {len(output_str)}")
                    logger.info(f"[DEBUG] æå–åˆ° {len(extracted_sources)} ä¸ªæ¥æº")
                    if extracted_sources:
                        logger.info(f"[DEBUG] æ¥æºç¤ºä¾‹: {extracted_sources[0]}")

                if extracted_sources:
                    logger.info(f"æå–åˆ° {len(extracted_sources)} ä¸ªçŸ¥è¯†åº“æ¥æº")
                    knowledge_sources.extend(extracted_sources)

                yield f"data: {json.dumps({'type': 'tool', 'tool_name': tool_name, 'status': 'completed'}, ensure_ascii=False)}\n\n"

        # å‘é€çŸ¥è¯†åº“æ¥æº
        if knowledge_sources and not sources_sent:
            yield f"data: {json.dumps({'type': 'sources', 'sources': knowledge_sources}, ensure_ascii=False)}\n\n"
            sources_sent = True

        # å‘é€ç»“æŸäº‹ä»¶
        total_time = time.time() - start_time
        end_data = {
            "type": "end",
            "thread_id": thread_id,
            "tools_used": tools_used,
            "tool_call_count": tool_call_count,
            "total_time": round(total_time, 2),
            "mode": request.mode,
        }
        logger.info(f"è¯·æ±‚å®Œæˆ [thread_id={thread_id}, mode={request.mode}, tools={len(tools_used)}, calls={tool_call_count}, time={total_time:.2f}s]")
        yield f"data: {json.dumps(end_data, ensure_ascii=False)}\n\n"

    except Exception as e:
        logger.error(f"æµå¼å“åº”ç”Ÿæˆé”™è¯¯: {e}")

        # å°è¯•å‘é€å·²æ”¶é›†çš„çŸ¥è¯†åº“æ¥æº
        if knowledge_sources and not sources_sent:
            try:
                yield f"data: {json.dumps({'type': 'sources', 'sources': knowledge_sources}, ensure_ascii=False)}\n\n"
            except:
                pass

        yield f"data: {json.dumps({'type': 'error', 'error': str(e)}, ensure_ascii=False)}\n\n"


# ==================== çŸ¥è¯†åº“æŸ¥è¯¢ç«¯ç‚¹ ====================

@router.get("/knowledge/documents", response_model=DocumentListResponse, tags=["çŸ¥è¯†åº“"])
async def list_documents():
    """åˆ—å‡ºå¯ç”¨æ–‡æ¡£"""
    try:
        cm = get_context_manager()
        cm._ensure_loaded()

        documents = []
        total_chunks = 0

        for source, doc_idx in cm.doc_index.items():
            preview = doc_idx.chunks_info[0]["content_preview"] if doc_idx.chunks_info else ""
            doc_info = DocumentInfo(
                source=source,
                type=doc_idx.doc_type,
                chunk_count=len(doc_idx.chunks_info),
                preview=preview,
            )
            documents.append(doc_info)
            total_chunks += len(doc_idx.chunks_info)

        return DocumentListResponse(
            documents=documents,
            total_count=len(documents),
            total_chunks=total_chunks,
        )

    except Exception as e:
        logger.error(f"è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {str(e)}"
        )


@router.get("/knowledge/summary/{source}", response_model=DocumentSummaryResponse, tags=["çŸ¥è¯†åº“"])
async def get_document_summary(source: str):
    """è·å–æ–‡æ¡£æ‰§è¡Œæ‘˜è¦"""
    try:
        cm = get_context_manager()
        result = cm.get_executive_summary(source)

        if "error" in result:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=result["error"]
            )

        return DocumentSummaryResponse(
            source=source,
            executive_summary=result.get("executive_summary") or "",
        )

    except FileNotFoundError:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"æ–‡æ¡£æœªæ‰¾åˆ°: {source}"
        )
    except Exception as e:
        logger.error(f"è·å–æ–‡æ¡£æ‘˜è¦å¤±è´¥: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–æ–‡æ¡£æ‘˜è¦å¤±è´¥: {str(e)}"
        )


@router.get("/knowledge/chapters/{source}", response_model=ChapterListResponse, tags=["çŸ¥è¯†åº“"])
async def get_document_chapters(source: str):
    """åˆ—å‡ºæ–‡æ¡£ç« èŠ‚æ‘˜è¦"""
    try:
        cm = get_context_manager()
        result = cm.list_chapter_summaries(source)

        if "error" in result:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=result["error"]
            )

        chapters = [
            ChapterInfo(
                header=ch["header"],
                summary=ch.get("summary", ""),
            )
            for ch in result.get("chapters", [])
        ]

        return ChapterListResponse(
            source=source,
            chapters=chapters,
        )

    except FileNotFoundError:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"æ–‡æ¡£æœªæ‰¾åˆ°: {source}"
        )
    except Exception as e:
        logger.error(f"è·å–ç« èŠ‚åˆ—è¡¨å¤±è´¥: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–ç« èŠ‚åˆ—è¡¨å¤±è´¥: {str(e)}"
        )
