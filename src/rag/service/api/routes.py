"""
Planning Service API è·¯ç”±
æä¾›è§„åˆ’å’¨è¯¢ã€çŸ¥è¯†åº“æŸ¥è¯¢ç­‰ç«¯ç‚¹
"""
import json
import logging
import uuid
from typing import AsyncGenerator
from datetime import datetime

from fastapi import APIRouter, HTTPException, status
from fastapi.responses import StreamingResponse, JSONResponse
from langchain_core.messages import HumanMessage

# å¯¼å…¥é…ç½®å’Œæ¨¡å‹
from src.rag.service.core.config import (
    SERVICE_NAME,
    SERVICE_VERSION,
    API_PREFIX,
    LOG_LEVEL,
)
from src.rag.service.schemas.chat import (
    PlanningChatRequest,
    PlanningChatResponse,
    DocumentListResponse,
    DocumentInfo,
    DocumentSummaryResponse,
    ChapterListResponse,
    ChapterInfo,
    HealthResponse,
    ErrorResponse,
)

# å¯¼å…¥ RAG æ ¸å¿ƒç»„ä»¶
from src.rag.core.context_manager import get_context_manager
from src.rag.core.tools import (
    executive_summary_tool,
    chapter_summaries_list_tool,
    chapter_summary_tool,
    key_points_search_tool,
)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=getattr(logging, LOG_LEVEL),
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# åˆ›å»ºè·¯ç”±å™¨
router = APIRouter()


# ==================== è¾…åŠ©å‡½æ•° ====================

def _extract_knowledge_sources(tool_output: str) -> list[dict]:
    """
    ä»å·¥å…·è¾“å‡ºä¸­æå–çŸ¥è¯†åº“æ¥æºä¿¡æ¯

    å·¥å…·è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
    ã€çŸ¥è¯†ç‰‡æ®µ 1ã€‘
    æ¥æº: ç½—æµ®-é•¿å®å±±é•‡èåˆå‘å±•æˆ˜ç•¥.pptx
    ä½ç½®: ç¬¬3 pptxï¼ˆæˆ– ç¬¬3é¡µã€ç¬¬4docxï¼‰
    å†…å®¹:
    ...

    Args:
        tool_output: å·¥å…·è¿”å›çš„æ–‡æœ¬

    Returns:
        æ¥æºä¿¡æ¯åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« source, page, content
    """
    import re

    sources = []

    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…çŸ¥è¯†ç‰‡æ®µ
    # åŒ¹é…æ ¼å¼ï¼šã€çŸ¥è¯†ç‰‡æ®µ Xã€‘æ¥æº: xxxä½ç½®: ç¬¬X [ç±»å‹]å†…å®¹:...
    # ä¼˜åŒ–ï¼šæ”¯æŒ "ç¬¬X ç±»å‹"ï¼ˆæœ‰ç©ºæ ¼ï¼‰å’Œ "ç¬¬Xç±»å‹"ï¼ˆæ— ç©ºæ ¼ï¼‰ä¸¤ç§æ ¼å¼
    # ä¿®å¤ï¼šæ”¹è¿› doc_type æå–ï¼Œé¿å…åªæå–éƒ¨åˆ†å­—ç¬¦ï¼ˆå¦‚ ptx è€Œä¸æ˜¯ pptxï¼‰
    # ä¿®å¤ï¼šç§»é™¤å†…å®¹åçš„ \n è¦æ±‚ï¼Œæ”¯æŒ "å†…å®¹: xxx" å’Œ "å†…å®¹:\nxxx" ä¸¤ç§æ ¼å¼
    pattern = r"ã€çŸ¥è¯†ç‰‡æ®µ \d+ã€‘\s*\næ¥æº: ([^\n]+)\s*\nä½ç½®: ç¬¬(\d+)\s*(.*?)\s*\nå†…å®¹:\s*([\s\S]*?)(?=ã€çŸ¥è¯†ç‰‡æ®µ|$)"

    matches = re.findall(pattern, tool_output)

    for match in matches:
        source, page_num, doc_type, content = match

        # æ¸…ç† doc_typeï¼ˆå»é™¤å‰å¯¼ç©ºç™½ï¼‰
        doc_type_clean = doc_type.strip() if doc_type else ""

        # æ¸…ç†å†…å®¹ï¼ˆå–å‰300ä¸ªå­—ç¬¦ä½œä¸ºé¢„è§ˆï¼‰
        content_preview = content.strip()[:300]
        if len(content_preview) == 300:
            content_preview += "..."

        sources.append({
            "source": source.strip(),
            "page": int(page_num),
            "doc_type": doc_type_clean,
            "content": content_preview,
        })

    return sources

# ==================== å»¶è¿ŸåŠ è½½ Planning Agent ====================
_agent = None


def get_agent():
    """å»¶è¿ŸåŠ è½½ Planning Agent"""
    global _agent
    if _agent is None:
        logger.info("æ­£åœ¨åŠ è½½ Planning Agent...")
        from src.agents.planning_agent import agent as planning_agent
        _agent = planning_agent
        logger.info("Planning Agent åŠ è½½å®Œæˆ")
    return _agent


# ==================== æ ¸å¿ƒç«¯ç‚¹ ====================

@router.get("/health", response_model=HealthResponse, tags=["ç³»ç»Ÿ"])
async def health_check():
    """
    å¥åº·æ£€æŸ¥ç«¯ç‚¹

    æ£€æŸ¥ Planning Service çš„è¿è¡ŒçŠ¶æ€ï¼ŒåŒ…æ‹¬ï¼š
    - æœåŠ¡çŠ¶æ€
    - çŸ¥è¯†åº“åŠ è½½çŠ¶æ€
    - æ¨¡å‹å¯ç”¨æ€§
    """
    try:
        # æ£€æŸ¥çŸ¥è¯†åº“
        from src.rag.config import CHROMA_PERSIST_DIR
        from pathlib import Path

        kb_loaded = Path(CHROMA_PERSIST_DIR).exists()

        return HealthResponse(
            status="healthy",
            service=SERVICE_NAME,
            version=SERVICE_VERSION,
            knowledge_base_loaded=kb_loaded,
        )
    except Exception as e:
        logger.error(f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail=f"æœåŠ¡ä¸å¯ç”¨: {str(e)}"
        )


@router.post(
    "/chat/planning",
    summary="è§„åˆ’å’¨è¯¢å¯¹è¯ï¼ˆæµå¼ï¼‰",
    description="é€šè¿‡ Planning Agent è¿›è¡Œä¹¡æ‘è§„åˆ’å’¨è¯¢ï¼Œæ”¯æŒæµå¼å“åº”",
    tags=["è§„åˆ’å’¨è¯¢"]
)
async def planning_chat(request: PlanningChatRequest):
    """
    # è§„åˆ’å’¨è¯¢å¯¹è¯æ¥å£ï¼ˆæµå¼ï¼‰

    åŸºäºçŸ¥è¯†åº“æä¾›ä¹¡æ‘è§„åˆ’å’¨è¯¢æœåŠ¡ï¼Œæ”¯æŒå¿«é€Ÿæ¨¡å¼å’Œæ·±åº¦æ¨¡å¼ã€‚

    ## å·¥ä½œæ¨¡å¼
    - **auto**: AI æ ¹æ®é—®é¢˜å¤æ‚åº¦è‡ªåŠ¨é€‰æ‹©æ¨¡å¼
    - **fast**: å¿«é€Ÿæµè§ˆæ¨¡å¼ï¼ˆä½¿ç”¨æ‘˜è¦å’Œè¦ç‚¹ï¼‰
    - **deep**: æ·±åº¦åˆ†ææ¨¡å¼ï¼ˆé˜…è¯»å®Œæ•´æ–‡æ¡£ï¼‰

    ## å“åº”æ ¼å¼
    ä½¿ç”¨ Server-Sent Events (SSE) æµå¼è¿”å›ï¼š
    - `start`: ä¼šè¯å¼€å§‹
    - `content`: AI å›å¤å†…å®¹ï¼ˆæµå¼ï¼‰
    - `tool`: å·¥å…·è°ƒç”¨ä¿¡æ¯
    - `end`: ä¼šè¯ç»“æŸ

    ## ç¤ºä¾‹
    ```bash
    curl -X POST "http://localhost:8003/api/v1/chat/planning" \
         -H "Content-Type: application/json" \
         -d '{"message": "é•¿å®é•‡çš„æ—…æ¸¸å‘å±•ç›®æ ‡æ˜¯ä»€ä¹ˆï¼Ÿ", "mode": "auto"}'
    ```
    """
    try:
        agent = get_agent()

        # ç”Ÿæˆæˆ–ä½¿ç”¨çº¿ç¨‹ID
        thread_id = request.thread_id or str(uuid.uuid4())
        config = {
            "configurable": {
                "thread_id": thread_id,
                "mode": request.mode,  # ä¼ é€’æ¨¡å¼åˆ° Agent é…ç½®
            }
        }

        logger.info(
            f"æ”¶åˆ°è§„åˆ’å’¨è¯¢è¯·æ±‚ [thread_id={thread_id}, mode={request.mode}]: {request.message}"
        )

        async def event_generator() -> AsyncGenerator[str, None]:
            """SSE äº‹ä»¶ç”Ÿæˆå™¨"""
            tools_used = []
            full_content = ""
            knowledge_sources = []  # æ”¶é›†æ‰€æœ‰çŸ¥è¯†åº“æ¥æº
            sources_sent = False  # æ ‡è®° sources æ˜¯å¦å·²å‘é€

            # æ·»åŠ æ€§èƒ½ç»Ÿè®¡
            import time
            start_time = time.time()
            tool_call_count = 0

            try:
                # å‘é€å¼€å§‹äº‹ä»¶
                yield f"data: {json.dumps({'type': 'start', 'thread_id': thread_id, 'mode': request.mode}, ensure_ascii=False)}\n\n"

                # æ¨¡å¼æŒ‡ä»¤å‰ç¼€ï¼ˆè®© Agent åœ¨è¿è¡Œæ—¶æ„ŸçŸ¥å½“å‰æ¨¡å¼ï¼‰
                mode_instructions = {
                    "fast": "âš¡ å½“å‰ä¸ºå¿«é€Ÿæ¨¡å¼ï¼šæœ€å¤šè°ƒç”¨ 2 æ¬¡å·¥å…·ï¼Œä¼˜å…ˆä½¿ç”¨ get_document_overview å’Œ search_key_pointsï¼Œé¿å…ä½¿ç”¨ get_chapter_content å’Œ get_document_fullã€‚",
                    "deep": "ğŸ” å½“å‰ä¸ºæ·±åº¦æ¨¡å¼ï¼šæœ€å¤šè°ƒç”¨ 5 æ¬¡å·¥å…·ï¼Œå¯ä»¥ä½¿ç”¨æ‰€æœ‰å·¥å…·åŒ…æ‹¬ get_chapter_content å’Œ get_document_full è¿›è¡Œæ·±åº¦åˆ†æã€‚",
                    "auto": "ğŸ¤– å½“å‰ä¸ºè‡ªåŠ¨æ¨¡å¼ï¼šæ ¹æ®é—®é¢˜å¤æ‚åº¦è‡ªä¸»é€‰æ‹©å·¥ä½œæ¨¡å¼å’Œå·¥å…·ã€‚"
                }

                # æ„å»ºå¸¦æœ‰æ¨¡å¼æŒ‡ä»¤çš„æ¶ˆæ¯
                mode_prefix = mode_instructions.get(request.mode, mode_instructions["auto"])
                enhanced_message = f"{mode_prefix}\n\nç”¨æˆ·é—®é¢˜ï¼š{request.message}"

                # å‡†å¤‡è¾“å…¥æ•°æ®ï¼ˆåŒ…å«æ¨¡å¼ï¼‰
                input_data = {
                    "messages": [HumanMessage(content=enhanced_message)],
                    "mode": request.mode,  # ä¼ é€’æ¨¡å¼åˆ°è¾“å…¥çŠ¶æ€
                }

                # æµå¼å¤„ç† agent å“åº”
                async for event in agent.astream_events(
                    input_data,
                    config,
                    version="v2",
                ):
                    kind = event["event"]

                    # å¤„ç†æµå¼æ¶ˆæ¯å†…å®¹
                    if kind == "on_chat_model_stream":
                        content = event["data"]["chunk"].content
                        if content:
                            full_content += content
                            event_data = {
                                "type": "content",
                                "content": content,
                            }
                            yield f"data: {json.dumps(event_data, ensure_ascii=False)}\n\n"

                    # å¤„ç†å·¥å…·è°ƒç”¨
                    elif kind == "on_tool_start":
                        tool_name = event["name"]
                        if tool_name not in tools_used:
                            tools_used.append(tool_name)
                        tool_call_count += 1  # ç»Ÿè®¡å·¥å…·è°ƒç”¨æ¬¡æ•°
                        event_data = {
                            "type": "tool",
                            "tool_name": tool_name,
                            "status": "started",
                            "tool_call_count": tool_call_count,  # æ·»åŠ è°ƒç”¨è®¡æ•°
                        }
                        yield f"data: {json.dumps(event_data, ensure_ascii=False)}\n\n"

                    elif kind == "on_tool_end":
                        tool_name = event["name"]
                        tool_output = event["data"].get("output")

                        # å°† ToolMessage å¯¹è±¡è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                        output_str = str(tool_output.content) if hasattr(tool_output, "content") else str(tool_output)

                        # è°ƒè¯•ï¼šè®°å½•å·¥å…·è¾“å‡ºï¼ˆåªè®°å½•å‰200å­—ç¬¦ï¼‰
                        logger.info(f"å·¥å…· {tool_name} è¾“å‡ºé¢„è§ˆ: {output_str[:200]}...")

                        # ä»å·¥å…·è¾“å‡ºä¸­æå–çŸ¥è¯†åº“æ¥æº
                        extracted_sources = _extract_knowledge_sources(output_str)

                        # è°ƒè¯•ï¼šè®°å½•æå–ç»“æœ
                        if tool_name == "search_knowledge":
                            logger.info(f"[DEBUG] search_knowledge è¾“å‡ºé•¿åº¦: {len(output_str)}")
                            logger.info(f"[DEBUG] æå–åˆ° {len(extracted_sources)} ä¸ªæ¥æº")
                            if extracted_sources:
                                logger.info(f"[DEBUG] æ¥æºç¤ºä¾‹: {extracted_sources[0]}")

                        if extracted_sources:
                            logger.info(f"æå–åˆ° {len(extracted_sources)} ä¸ªçŸ¥è¯†åº“æ¥æº")
                            knowledge_sources.extend(extracted_sources)

                        event_data = {
                            "type": "tool",
                            "tool_name": tool_name,
                            "status": "completed",
                        }
                        yield f"data: {json.dumps(event_data, ensure_ascii=False)}\n\n"

                # å‘é€çŸ¥è¯†åº“æ¥æºï¼ˆåœ¨æ­£å¸¸æµç¨‹ç»“æŸæ—¶ï¼‰
                if knowledge_sources and not sources_sent:
                    sources_data = {
                        "type": "sources",
                        "sources": knowledge_sources,
                    }
                    yield f"data: {json.dumps(sources_data, ensure_ascii=False)}\n\n"
                    sources_sent = True

                # è®¡ç®—æ€»è€—æ—¶
                total_time = time.time() - start_time

                # å‘é€ç»“æŸäº‹ä»¶ï¼ˆåŒ…å«æ€§èƒ½ç»Ÿè®¡ï¼‰
                end_data = {
                    "type": "end",
                    "thread_id": thread_id,
                    "tools_used": tools_used,
                    "tool_call_count": tool_call_count,  # å·¥å…·è°ƒç”¨æ€»æ¬¡æ•°
                    "total_time": round(total_time, 2),  # æ€»è€—æ—¶ï¼ˆç§’ï¼‰
                    "mode": request.mode,
                }
                logger.info(
                    f"è¯·æ±‚å®Œæˆ [thread_id={thread_id}, mode={request.mode}, "
                    f"tools={len(tools_used)}, calls={tool_call_count}, time={total_time:.2f}s]"
                )
                yield f"data: {json.dumps(end_data, ensure_ascii=False)}\n\n"

            except Exception as e:
                logger.error(f"æµå¼å“åº”ç”Ÿæˆé”™è¯¯: {e}")

                # åœ¨é”™è¯¯å‘ç”Ÿå‰å°è¯•å‘é€å·²æ”¶é›†çš„çŸ¥è¯†åº“æ¥æº
                if knowledge_sources and not sources_sent:
                    sources_data = {
                        "type": "sources",
                        "sources": knowledge_sources,
                    }
                    try:
                        yield f"data: {json.dumps(sources_data, ensure_ascii=False)}\n\n"
                    except:
                        pass  # å¦‚æœå‘é€å¤±è´¥ï¼Œå¿½ç•¥

                error_data = {
                    "type": "error",
                    "error": str(e),
                }
                yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"

        return StreamingResponse(
            event_generator(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no",
            }
        )

    except Exception as e:
        logger.error(f"è§„åˆ’å’¨è¯¢è¯·æ±‚å¤±è´¥: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è¯·æ±‚å¤„ç†å¤±è´¥: {str(e)}"
        )


# ==================== çŸ¥è¯†åº“æŸ¥è¯¢ç«¯ç‚¹ ====================

@router.get(
    "/knowledge/documents",
    response_model=DocumentListResponse,
    summary="åˆ—å‡ºå¯ç”¨æ–‡æ¡£",
    description="è·å–çŸ¥è¯†åº“ä¸­æ‰€æœ‰å¯ç”¨çš„æ–‡æ¡£åˆ—è¡¨",
    tags=["çŸ¥è¯†åº“"]
)
async def list_documents():
    """
    # åˆ—å‡ºå¯ç”¨æ–‡æ¡£

    è¿”å›çŸ¥è¯†åº“ä¸­æ‰€æœ‰æ–‡æ¡£çš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
    - æ–‡æ¡£åç§°
    - æ–‡æ¡£ç±»å‹ï¼ˆæ”¿ç­–/æ¡ˆä¾‹ï¼‰
    - åˆ‡ç‰‡æ•°é‡
    - å†…å®¹é¢„è§ˆ
    """
    try:
        # ç›´æ¥ä½¿ç”¨ ContextManager è·å–æ–‡æ¡£åˆ—è¡¨
        cm = get_context_manager()
        cm._ensure_loaded()

        documents = []
        total_chunks = 0

        for source, doc_idx in cm.doc_index.items():
            doc_info = DocumentInfo(
                source=source,
                type=doc_idx.doc_type,
                chunk_count=len(doc_idx.chunks_info),
                preview=doc_idx.chunks_info[0]["content_preview"] if doc_idx.chunks_info else "",
            )
            documents.append(doc_info)
            total_chunks += len(doc_idx.chunks_info)

        return DocumentListResponse(
            documents=documents,
            total_count=len(documents),
            total_chunks=total_chunks,
        )

    except Exception as e:
        logger.error(f"è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {str(e)}"
        )


@router.get(
    "/knowledge/summary/{source}",
    response_model=DocumentSummaryResponse,
    summary="è·å–æ–‡æ¡£æ‰§è¡Œæ‘˜è¦",
    description="è·å–æŒ‡å®šæ–‡æ¡£çš„200å­—æ‰§è¡Œæ‘˜è¦",
    tags=["çŸ¥è¯†åº“"]
)
async def get_document_summary(source: str):
    """
    # è·å–æ–‡æ¡£æ‰§è¡Œæ‘˜è¦

    è¿”å›æ–‡æ¡£çš„æ‰§è¡Œæ‘˜è¦ï¼ŒåŒ…å«ï¼š
    - æ ¸å¿ƒç›®æ ‡
    - å®šä½
    - å…³é”®æŒ‡æ ‡
    - é‡ç‚¹æªæ–½

    ## å‚æ•°
    - **source**: æ–‡æ¡£æ–‡ä»¶åï¼ˆéœ€è¦è¿›è¡Œ URL ç¼–ç ï¼‰

    ## ç¤ºä¾‹
    ```bash
    curl "http://localhost:8003/api/v1/knowledge/summary/ç½—æµ®-é•¿å®å±±é•‡èåˆå‘å±•æˆ˜ç•¥.pptx"
    ```
    """
    try:
        # ç›´æ¥ä½¿ç”¨ ContextManager
        cm = get_context_manager()
        result = cm.get_executive_summary(source)

        if "error" in result:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=result["error"]
            )

        return DocumentSummaryResponse(
            source=source,
            executive_summary=result.get("executive_summary") or "",
        )

    except FileNotFoundError:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"æ–‡æ¡£æœªæ‰¾åˆ°: {source}"
        )
    except Exception as e:
        logger.error(f"è·å–æ–‡æ¡£æ‘˜è¦å¤±è´¥: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–æ–‡æ¡£æ‘˜è¦å¤±è´¥: {str(e)}"
        )


@router.get(
    "/knowledge/chapters/{source}",
    response_model=ChapterListResponse,
    summary="åˆ—å‡ºæ–‡æ¡£ç« èŠ‚æ‘˜è¦",
    description="è·å–æŒ‡å®šæ–‡æ¡£çš„æ‰€æœ‰ç« èŠ‚åŠå…¶æ‘˜è¦",
    tags=["çŸ¥è¯†åº“"]
)
async def get_document_chapters(source: str):
    """
    # åˆ—å‡ºæ–‡æ¡£ç« èŠ‚æ‘˜è¦

    è¿”å›æ–‡æ¡£çš„æ‰€æœ‰ç« èŠ‚ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
    - ç« èŠ‚æ ‡é¢˜
    - ç« èŠ‚æ‘˜è¦

    ## å‚æ•°
    - **source**: æ–‡æ¡£æ–‡ä»¶åï¼ˆéœ€è¦è¿›è¡Œ URL ç¼–ç ï¼‰

    ## ç¤ºä¾‹
    ```bash
    curl "http://localhost:8003/api/v1/knowledge/chapters/ç½—æµ®-é•¿å®å±±é•‡èåˆå‘å±•æˆ˜ç•¥.pptx"
    ```
    """
    try:
        # ç›´æ¥ä½¿ç”¨ ContextManager
        cm = get_context_manager()
        result = cm.list_chapter_summaries(source)

        if "error" in result:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=result["error"]
            )

        chapters = []
        for ch in result.get("chapters", []):
            chapter_info = ChapterInfo(
                header=ch["header"],
                summary=ch.get("summary", ""),
            )
            chapters.append(chapter_info)

        return ChapterListResponse(
            source=source,
            chapters=chapters,
        )

    except FileNotFoundError:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"æ–‡æ¡£æœªæ‰¾åˆ°: {source}"
        )
    except Exception as e:
        logger.error(f"è·å–ç« èŠ‚åˆ—è¡¨å¤±è´¥: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–ç« èŠ‚åˆ—è¡¨å¤±è´¥: {str(e)}"
        )


# ==================== é”™è¯¯å¤„ç† ====================
# æ³¨æ„ï¼šå…¨å±€å¼‚å¸¸å¤„ç†åœ¨ FastAPI åº”ç”¨å±‚ï¼ˆmain.pyï¼‰é…ç½®ï¼Œä¸åœ¨è·¯ç”±å±‚é…ç½®
