import os
from langchain_core.tools import Tool
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings

# è·¯å¾„é…ç½® (è‡ªåŠ¨æŒ‡å‘åˆšæ‰å»ºå¥½çš„åº“)
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
DB_PATH = os.path.join(PROJECT_ROOT, "knowledge_base", "luofu_db")

# åˆå§‹åŒ– Embeddings (é¿å…æ¯æ¬¡è°ƒç”¨éƒ½é‡æ–°åŠ è½½)
_embedding_model = None
_vectorstore = None

def get_vectorstore():
    """æ‡’åŠ è½½æ•°æ®åº“ï¼ŒèŠ‚çœå¯åŠ¨èµ„æº"""
    global _embedding_model, _vectorstore
    if _vectorstore is None:
        print("ğŸ“¥ æ­£åœ¨åŠ è½½çŸ¥è¯†åº“...")
        _embedding_model = HuggingFaceEmbeddings(model_name="BAAI/bge-small-zh-v1.5")
        _vectorstore = Chroma(persist_directory=DB_PATH, embedding_function=_embedding_model)
    return _vectorstore

def retrieve_planning_info(query: str) -> str:
    """
    RAG æ ¸å¿ƒæ£€ç´¢å‡½æ•°
    """
    try:
        db = get_vectorstore()
        # æœç´¢æœ€ç›¸å…³çš„ 3 ä¸ªç‰‡æ®µ
        results = db.similarity_search(query, k=3)
        
        if not results:
            return "çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"
            
        # æ‹¼æ¥ç»“æœï¼Œå‘Šè¯‰å¤§æ¨¡å‹è¿™æ˜¯ä»å“ªä¸€é¡µæŸ¥åˆ°çš„
        context_parts = []
        for doc in results:
            page = doc.metadata.get('page', 'æœªçŸ¥')
            context_parts.append(f"[ç¬¬{page}é¡µå†…å®¹]: {doc.page_content}")
            
        return "\n\n".join(context_parts)
    except Exception as e:
        return f"æŸ¥è¯¢çŸ¥è¯†åº“æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"

# ================= å®šä¹‰ Agent å¯ç”¨çš„å·¥å…· =================
# è¿™ä¸ªå˜é‡å¯ä»¥ç›´æ¥ import åˆ°ä½ çš„ agent ä»£ç é‡Œ
planning_knowledge_tool = Tool(
    name="search_planning_strategy",
    func=retrieve_planning_info,
    description="ã€å¿…é¡»ä½¿ç”¨ã€‘å½“ç”¨æˆ·è¯¢é—®å…³äº'åšç½—å¤åŸ'ã€'é•¿å®é•‡'ã€'ç½—æµ®å±±'çš„è§„åˆ’è®¾è®¡ã€æˆ˜ç•¥å®šä½ã€ç°çŠ¶åˆ†ææˆ–å†å²æ–‡åŒ–æ—¶ï¼Œä½¿ç”¨æ­¤å·¥å…·æŸ¥è¯¢çŸ¥è¯†åº“ã€‚"
)