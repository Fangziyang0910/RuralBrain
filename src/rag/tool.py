"""
çŸ¥è¯†åº“æ£€ç´¢å·¥å…·ï¼ˆé€‚é… Planning Agentï¼‰
ä½¿ç”¨ Agentic RAG æ¨¡å¼ï¼Œè®© LLM è‡ªä¸»å†³å®šä½•æ—¶æ£€ç´¢
æ”¯æŒæ•´ä½“å±‚é¢çŸ¥è¯†è¯»å–ï¼Œæ›´é€‚åˆå¤æ‚å†³ç­–åœºæ™¯
"""
import os
from pathlib import Path
from typing import List

from langchain_core.documents import Document
from langchain_core.tools import Tool
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings

# å¯¼å…¥é…ç½®
import sys
sys.path.append(str(Path(__file__).parent.parent.parent))

from src.rag.config import (
    CHROMA_COLLECTION_NAME,
    CHROMA_PERSIST_DIR,
    DEFAULT_TOP_K,
    EMBEDDING_MODEL_NAME,
)

# å…¨å±€å˜é‡ï¼ˆæ‡’åŠ è½½ï¼‰
_embedding_model = None
_vectorstore = None


def get_vectorstore():
    """
    æ‡’åŠ è½½å‘é‡æ•°æ®åº“
    é¿å…æ¯æ¬¡è°ƒç”¨éƒ½é‡æ–°åŠ è½½æ¨¡å‹
    """
    global _embedding_model, _vectorstore

    if _vectorstore is None:
        print("ğŸ“¥ æ­£åœ¨åŠ è½½çŸ¥è¯†åº“...")

        # åˆå§‹åŒ– Embedding æ¨¡å‹
        _embedding_model = HuggingFaceEmbeddings(
            model_name=EMBEDDING_MODEL_NAME,
            encode_kwargs={"normalize_embeddings": True},
        )

        # åŠ è½½å‘é‡æ•°æ®åº“
        if not CHROMA_PERSIST_DIR.exists():
            raise FileNotFoundError(
                f"çŸ¥è¯†åº“ä¸å­˜åœ¨: {CHROMA_PERSIST_DIR}\n"
                f"è¯·å…ˆè¿è¡Œ: python src/rag/build.py"
            )

        _vectorstore = Chroma(
            persist_directory=str(CHROMA_PERSIST_DIR),
            embedding_function=_embedding_model,
            collection_name=CHROMA_COLLECTION_NAME,
        )

        print(f"âœ… çŸ¥è¯†åº“åŠ è½½å®Œæˆï¼ˆé›†åˆ: {CHROMA_COLLECTION_NAME}ï¼‰")

    return _vectorstore


def retrieve_planning_knowledge(query: str, top_k: int = DEFAULT_TOP_K) -> str:
    """
    æ£€ç´¢ä¹¡æ‘è§„åˆ’ç›¸å…³çŸ¥è¯†ï¼ˆé€‚é… Planning Agentï¼‰

    Args:
        query: æŸ¥è¯¢é—®é¢˜
        top_k: è¿”å›çš„åˆ‡ç‰‡æ•°é‡ï¼ˆPlanning Agent éœ€è¦æ›´å¤šä¸Šä¸‹æ–‡ï¼‰

    Returns:
        æ ¼å¼åŒ–çš„æ£€ç´¢ç»“æœ
    """
    try:
        db = get_vectorstore()

        # ä½¿ç”¨æ›´é«˜çš„ k å€¼è·å–æ›´å¤šä¸Šä¸‹æ–‡ï¼ˆé€‚åˆ Planning Agentï¼‰
        results: List[Document] = db.similarity_search(query, k=top_k)

        if not results:
            return "âš ï¸  çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"

        # æ ¼å¼åŒ–ç»“æœï¼Œæä¾›æ›´ä¸°å¯Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        context_parts = []
        for idx, doc in enumerate(results, 1):
            # æå–å…ƒæ•°æ®
            source = doc.metadata.get("source", "æœªçŸ¥æ¥æº")
            page = doc.metadata.get("page", doc.metadata.get("paragraph", "æœªçŸ¥"))
            doc_type = doc.metadata.get("type", "æœªçŸ¥ç±»å‹")

            # æ„å»ºä¸Šä¸‹æ–‡ç‰‡æ®µ
            context_part = (
                f"ã€çŸ¥è¯†ç‰‡æ®µ {idx}ã€‘\n"
                f"æ¥æº: {source}\n"
                f"ä½ç½®: ç¬¬{page}{doc_type}\n"
                f"å†…å®¹:\n{doc.page_content}"
            )
            context_parts.append(context_part)

        return "\n\n".join(context_parts)

    except Exception as e:
        return f"âŒ æŸ¥è¯¢çŸ¥è¯†åº“æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"


def retrieve_with_metadata(
    query: str,
    top_k: int = DEFAULT_TOP_K,
    source_filter: str | None = None,
):
    """
    å¸¦å…ƒæ•°æ®è¿‡æ»¤çš„æ£€ç´¢ï¼ˆé«˜çº§ç”¨æ³•ï¼‰

    Args:
        query: æŸ¥è¯¢é—®é¢˜
        top_k: è¿”å›çš„åˆ‡ç‰‡æ•°é‡
        source_filter: æŒ‰æ¥æºè¿‡æ»¤ï¼ˆä¾‹å¦‚ï¼š"luofu_strategy.pptx"ï¼‰

    Returns:
        æ–‡æ¡£åˆ—è¡¨ï¼ˆåŒ…å«å®Œæ•´å…ƒæ•°æ®ï¼‰
    """
    try:
        db = get_vectorstore()

        # æ„å»ºè¿‡æ»¤æ¡ä»¶
        if source_filter:
            # ä½¿ç”¨å…ƒæ•°æ®è¿‡æ»¤
            results = db.similarity_search(
                query,
                k=top_k,
                filter={"source": source_filter},
            )
        else:
            results = db.similarity_search(query, k=top_k)

        return results

    except Exception as e:
        print(f"âŒ æ£€ç´¢å¤±è´¥: {e}")
        return []


# ==================== LangChain Tool å®šä¹‰ ====================
# è¿™ä¸ª Tool å¯ä»¥ç›´æ¥é›†æˆåˆ° Agent ä¸­

planning_knowledge_tool = Tool(
    name="search_rural_planning_knowledge",
    func=retrieve_planning_knowledge,
    description=(
        "ã€ä¹¡æ‘è§„åˆ’çŸ¥è¯†åº“ã€‘"
        "å½“ç”¨æˆ·è¯¢é—®å…³äºä¹¡æ‘è§„åˆ’ã€å†œä¸šå‘å±•ã€äº§ä¸šå¸ƒå±€ã€å†å²æ–‡åŒ–ã€"
        "æ—…æ¸¸å¼€å‘ã€æ”¿ç­–è§£è¯»ç­‰éœ€è¦å®è§‚å†³ç­–çš„é—®é¢˜æ—¶ï¼Œä½¿ç”¨æ­¤å·¥å…·ã€‚"
        "è¯¥å·¥å…·ä¼šè¿”å›ç›¸å…³çš„çŸ¥è¯†ç‰‡æ®µï¼Œå¸®åŠ©ä½ åšå‡ºæ›´å…¨é¢çš„è§„åˆ’å’Œå†³ç­–ã€‚"
        "\n\n"
        "ä½¿ç”¨åœºæ™¯ç¤ºä¾‹ï¼š"
        '- "åšç½—å¤åŸçš„å‘å±•å®šä½æ˜¯ä»€ä¹ˆï¼Ÿ"'
        '- "å¦‚ä½•è§„åˆ’ä¹¡æ‘æ—…æ¸¸äº§ä¸šï¼Ÿ"'
        '- "å½“åœ°æœ‰å“ªäº›å†å²æ–‡åŒ–èµ„æºï¼Ÿ"'
    ),
)

# ä¹Ÿå¯ä»¥ä½¿ç”¨ response_format="content_and_artifact" æ¨¡å¼ï¼ˆAgentic RAGï¼‰
# è®© LLM èƒ½å¤Ÿçœ‹åˆ°åŸå§‹æ–‡æ¡£å¯¹è±¡
from langchain_core.tools import tool

@tool(response_format="content_and_artifact")
def retrieve_knowledge_detailed(query: str) -> tuple[str, List[Document]]:
    """
    æ£€ç´¢çŸ¥è¯†ï¼ˆAgentic RAG æ¨¡å¼ï¼‰
    è¿”å›æ ¼å¼åŒ–æ–‡æœ¬ + åŸå§‹æ–‡æ¡£å¯¹è±¡
    """
    db = get_vectorstore()
    retrieved_docs = db.similarity_search(query, k=DEFAULT_TOP_K)

    # æ ¼å¼åŒ–å†…å®¹
    serialized = "\n\n".join(
        f"æ¥æº: {doc.metadata.get('source', 'æœªçŸ¥')}\n"
        f"ä½ç½®: {doc.metadata.get('page', doc.metadata.get('paragraph', 'æœªçŸ¥'))}\n"
        f"å†…å®¹: {doc.page_content}"
        for doc in retrieved_docs
    )

    return serialized, retrieved_docs
