"""
RAG çŸ¥è¯†åº“æ¨¡å—åŠŸèƒ½æµ‹è¯•
æµ‹è¯•æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""
import sys
from pathlib import Path

sys.path.append(str(Path(__file__).parent.parent.parent))

from src.rag.utils import load_documents_from_directory, PPTXLoader, TextFileLoader
from src.rag.config import DATA_DIR, CHUNK_SIZE, CHUNK_OVERLAP
from langchain_text_splitters import RecursiveCharacterTextSplitter


def test_document_loading():
    """æµ‹è¯•æ–‡æ¡£åŠ è½½åŠŸèƒ½"""
    print("="*60)
    print("æµ‹è¯• 1: æ–‡æ¡£åŠ è½½åŠŸèƒ½")
    print("="*60)

    try:
        # æµ‹è¯•ä»ç›®å½•æ‰¹é‡åŠ è½½
        documents = load_documents_from_directory(
            DATA_DIR,
            file_extensions=[".txt"]
        )

        print(f"\nâœ… æˆåŠŸåŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£ç‰‡æ®µ")

        # æ˜¾ç¤ºå‰å‡ ä¸ªæ–‡æ¡£
        for i, doc in enumerate(documents[:3]):
            print(f"\n--- æ–‡æ¡£ {i+1} ---")
            print(f"æ¥æº: {doc.metadata.get('source')}")
            print(f"ä½ç½®: {doc.metadata.get('paragraph', doc.metadata.get('page', 'æœªçŸ¥'))}")
            print(f"å†…å®¹é•¿åº¦: {len(doc.page_content)} å­—ç¬¦")
            print(f"å†…å®¹é¢„è§ˆ: {doc.page_content[:100]}...")

        return documents

    except Exception as e:
        print(f"\nâŒ æ–‡æ¡£åŠ è½½å¤±è´¥: {e}")
        return None


def test_text_splitting(documents):
    """æµ‹è¯•æ–‡æ¡£åˆ‡åˆ†åŠŸèƒ½"""
    print("\n" + "="*60)
    print("æµ‹è¯• 2: æ–‡æ¡£åˆ‡åˆ†åŠŸèƒ½")
    print("="*60)

    try:
        print(f"\né…ç½®: chunk_size={CHUNK_SIZE}, chunk_overlap={CHUNK_OVERLAP}")

        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=CHUNK_SIZE,
            chunk_overlap=CHUNK_OVERLAP,
            length_function=len,
            add_start_index=True,
        )

        splits = text_splitter.split_documents(documents)
        print(f"\nâœ… æˆåŠŸåˆ‡åˆ†ä¸º {len(splits)} ä¸ªåˆ‡ç‰‡")

        # æ˜¾ç¤ºå‰å‡ ä¸ªåˆ‡ç‰‡
        for i, split in enumerate(splits[:3]):
            print(f"\n--- åˆ‡ç‰‡ {i+1} ---")
            print(f"æ¥æº: {split.metadata.get('source')}")
            print(f"å†…å®¹é•¿åº¦: {len(split.page_content)} å­—ç¬¦")
            print(f"å†…å®¹é¢„è§ˆ: {split.page_content[:150]}...")

        return splits

    except Exception as e:
        print(f"\nâŒ æ–‡æ¡£åˆ‡åˆ†å¤±è´¥: {e}")
        return None


def test_slice_inspector(splits):
    """æµ‹è¯•åˆ‡ç‰‡å¯è§†åŒ–å·¥å…·"""
    print("\n" + "="*60)
    print("æµ‹è¯• 3: åˆ‡ç‰‡å¯è§†åŒ–å·¥å…·")
    print("="*60)

    try:
        from src.rag.visualize import SliceInspector

        inspector = SliceInspector(splits)

        print("\nğŸ“Š åˆ‡ç‰‡ç»Ÿè®¡:")
        inspector.print_summary()

        print("\nğŸ” æŸ¥çœ‹å‰ 2 ä¸ªåˆ‡ç‰‡çš„è¯¦æƒ…:")
        inspector.print_slice_details(start_idx=0, end_idx=2, show_content=False)

        print("\nâš ï¸  æ½œåœ¨é—®é¢˜æ£€æµ‹:")
        inspector.print_issues(max_issues=5)

        # å¯¼å‡º JSON
        json_path = DATA_DIR / "test_slices_analysis.json"
        inspector.export_to_json(json_path)
        print(f"\nâœ… åˆ‡ç‰‡åˆ†æå·²å¯¼å‡ºåˆ°: {json_path}")

        return True

    except Exception as e:
        print(f"\nâŒ åˆ‡ç‰‡å¯è§†åŒ–å¤±è´¥: {e}")
        return False


def test_vector_store_build(splits):
    """æµ‹è¯•å‘é‡åº“æ„å»º"""
    print("\n" + "="*60)
    print("æµ‹è¯• 4: å‘é‡åº“æ„å»º")
    print("="*60)

    try:
        from src.rag.build import build_vector_store

        vectorstore = build_vector_store(splits)
        print("\nâœ… å‘é‡åº“æ„å»ºæˆåŠŸ")

        return vectorstore

    except Exception as e:
        print(f"\nâŒ å‘é‡åº“æ„å»ºå¤±è´¥: {e}")
        return None


def test_basic_retrieval():
    """æµ‹è¯•åŸºç¡€æ£€ç´¢åŠŸèƒ½"""
    print("\n" + "="*60)
    print("æµ‹è¯• 5: åŸºç¡€æ£€ç´¢åŠŸèƒ½")
    print("="*60)

    try:
        from src.rag.core.tools import retrieve_planning_knowledge

        # æµ‹è¯•æŸ¥è¯¢
        test_queries = [
            "ç½—æµ®å±±çš„å‘å±•å®šä½æ˜¯ä»€ä¹ˆï¼Ÿ",
            "åšç½—å¿çš„ç°ä»£å†œä¸šæœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿ",
            "å¦‚ä½•ä¿æŠ¤ç½—æµ®å±±çš„ç”Ÿæ€ç¯å¢ƒï¼Ÿ"
        ]

        for query in test_queries:
            print(f"\nğŸ” æŸ¥è¯¢: {query}")
            result = retrieve_planning_knowledge(query, top_k=2)
            print(f"\nğŸ“ ç»“æœé¢„è§ˆ (å‰ 500 å­—ç¬¦):")
            print(result[:500] + "..." if len(result) > 500 else result)
            print("-" * 60)

        print("\nâœ… åŸºç¡€æ£€ç´¢åŠŸèƒ½æ­£å¸¸")

        return True

    except Exception as e:
        print(f"\nâŒ åŸºç¡€æ£€ç´¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_metadata_filter_retrieval():
    """æµ‹è¯•å…ƒæ•°æ®è¿‡æ»¤æ£€ç´¢"""
    print("\n" + "="*60)
    print("æµ‹è¯• 6: å…ƒæ•°æ®è¿‡æ»¤æ£€ç´¢")
    print("="*60)

    try:
        from src.rag.core.tools import retrieve_with_metadata

        # æµ‹è¯•å…ƒæ•°æ®è¿‡æ»¤
        query = "å‘å±•è§„åˆ’"
        source = "test_planning.txt"

        print(f"\nğŸ” æŸ¥è¯¢: {query}")
        print(f"ğŸ¯ è¿‡æ»¤æ¡ä»¶: source={source}")

        results = retrieve_with_metadata(query, top_k=3, source_filter=source)

        print(f"\nâœ… æ£€ç´¢åˆ° {len(results)} ä¸ªç»“æœ")

        for i, doc in enumerate(results[:2]):
            print(f"\n--- ç»“æœ {i+1} ---")
            print(f"æ¥æº: {doc.metadata.get('source')}")
            print(f"ä½ç½®: {doc.metadata.get('paragraph', doc.metadata.get('page'))}")
            print(f"å†…å®¹: {doc.page_content[:200]}...")

        return True

    except Exception as e:
        print(f"\nâŒ å…ƒæ•°æ®è¿‡æ»¤æ£€ç´¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_langchain_tool():
    """æµ‹è¯• LangChain Tool é›†æˆ"""
    print("\n" + "="*60)
    print("æµ‹è¯• 7: LangChain Tool é›†æˆ")
    print("="*60)

    try:
        from src.rag.core.tools import planning_knowledge_tool

        print(f"\nğŸ”§ Tool åç§°: {planning_knowledge_tool.name}")
        print(f"ğŸ“ Tool æè¿°: {planning_knowledge_tool.description[:200]}...")

        # æµ‹è¯•å·¥å…·è°ƒç”¨
        query = "ç½—æµ®å±±çš„æ—…æ¸¸äº§ä¸šæœ‰ä»€ä¹ˆç‰¹è‰²ï¼Ÿ"
        print(f"\nğŸ” è°ƒç”¨ Tool: {query}")

        result = planning_knowledge_tool.run(query)
        print(f"\nğŸ“ ç»“æœé¢„è§ˆ (å‰ 500 å­—ç¬¦):")
        print(result[:500] + "..." if len(result) > 500 else result)

        print("\nâœ… LangChain Tool é›†æˆæ­£å¸¸")

        return True

    except Exception as e:
        print(f"\nâŒ LangChain Tool æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "="*60)
    print("ğŸš€ RAG çŸ¥è¯†åº“æ¨¡å—åŠŸèƒ½æµ‹è¯•")
    print("="*60)

    results = {
        "æ–‡æ¡£åŠ è½½": False,
        "æ–‡æ¡£åˆ‡åˆ†": False,
        "åˆ‡ç‰‡å¯è§†åŒ–": False,
        "å‘é‡åº“æ„å»º": False,
        "åŸºç¡€æ£€ç´¢": False,
        "å…ƒæ•°æ®è¿‡æ»¤": False,
        "LangChain Tool": False,
    }

    # 1. æµ‹è¯•æ–‡æ¡£åŠ è½½
    documents = test_document_loading()
    if documents:
        results["æ–‡æ¡£åŠ è½½"] = True

        # 2. æµ‹è¯•æ–‡æ¡£åˆ‡åˆ†
        splits = test_text_splitting(documents)
        if splits:
            results["æ–‡æ¡£åˆ‡åˆ†"] = True

            # 3. æµ‹è¯•åˆ‡ç‰‡å¯è§†åŒ–
            if test_slice_inspector(splits):
                results["åˆ‡ç‰‡å¯è§†åŒ–"] = True

            # 4. æµ‹è¯•å‘é‡åº“æ„å»º
            vectorstore = test_vector_store_build(splits)
            if vectorstore:
                results["å‘é‡åº“æ„å»º"] = True

                # 5-7. æµ‹è¯•æ£€ç´¢åŠŸèƒ½
                results["åŸºç¡€æ£€ç´¢"] = test_basic_retrieval()
                results["å…ƒæ•°æ®è¿‡æ»¤"] = test_metadata_filter_retrieval()
                results["LangChain Tool"] = test_langchain_tool()

    # è¾“å‡ºæµ‹è¯•ç»“æœæ±‡æ€»
    print("\n" + "="*60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print("="*60)

    for test_name, passed in results.items():
        status = "âœ… é€šè¿‡" if passed else "âŒ å¤±è´¥"
        print(f"{test_name}: {status}")

    total_tests = len(results)
    passed_tests = sum(results.values())

    print(f"\næ€»è®¡: {passed_tests}/{total_tests} ä¸ªæµ‹è¯•é€šè¿‡")

    if passed_tests == total_tests:
        print("\nğŸ‰ æ‰€æœ‰åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
    else:
        print(f"\nâš ï¸  æœ‰ {total_tests - passed_tests} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥")


if __name__ == "__main__":
    main()
